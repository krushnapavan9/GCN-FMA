{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_songs_map=open(\"genres_vs_songs.json\")\n",
    "genres_songs_map=json.load(genres_songs_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classical-- 1000\n",
      "Electronic-- 1000\n",
      "Experimental-- 1000\n",
      "Folk-- 1000\n",
      "Hip-Hop-- 1000\n",
      "Instrumental-- 1000\n",
      "International-- 1000\n",
      "Jazz-- 1000\n",
      "Pop-- 1000\n",
      "Rock-- 1000\n"
     ]
    }
   ],
   "source": [
    "for i in genres_songs_map:\n",
    "    print(i+\"-- %d\"%(len(genres_songs_map[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_index_map=dict()\n",
    "song_genres_map=dict()\n",
    "for i in genres_songs_map.values():\n",
    "    for j in i:\n",
    "        song_genres_map[j]=list()\n",
    "for i in genres_songs_map:\n",
    "    for j in genres_songs_map[i]:\n",
    "        song_genres_map[j].append(i)\n",
    "aux=0\n",
    "for i in song_genres_map:\n",
    "    song_index_map[i]=aux\n",
    "    aux=aux+1\n",
    "index_song_map=dict()\n",
    "for i in song_index_map:\n",
    "    index_song_map[song_index_map[i]]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9425\n",
      "283\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "one_gener_song=list()\n",
    "more_than_one_gener_song=list()\n",
    "count_one=0\n",
    "count_two=0\n",
    "count_more_than_two=0\n",
    "for i in song_genres_map.values():\n",
    "    if(len(i)==1):count_one=count_one+1\n",
    "    elif(len(i)==2): count_two=count_two+1\n",
    "    else: count_more_than_two=count_more_than_two+1\n",
    "for i in song_genres_map:\n",
    "    if(len(song_genres_map[i])==1):one_gener_song.append(i)\n",
    "    else: more_than_one_gener_song.append(i)\n",
    "print(count_one)\n",
    "print(count_two)\n",
    "print(count_more_than_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=dict()\n",
    "test=dict()\n",
    "validation=dict()\n",
    "train=dict()\n",
    "for i in genres_songs_map.keys():\n",
    "    temp[i]=list()\n",
    "    test[i]=list()\n",
    "    validation[i]=list()\n",
    "    train[i]=list()\n",
    "for i in one_gener_song:\n",
    "    temp[song_genres_map[i][0]].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from random import sample \n",
    "\n",
    "random.seed(1)\n",
    "for i in temp:\n",
    "    aux=sample(temp[i],int(len(temp[i])*0.3))\n",
    "    test[i]=aux[0:int(len(aux)/2)]\n",
    "    validation[i]=aux[int(len(aux)/2):]\n",
    "    for j in temp[i]:\n",
    "        if(j not in aux): train[i].append(j)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in more_than_one_gener_song:\n",
    "    for j in song_genres_map[i]:\n",
    "        train[j].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classical-- Train:  717, Validation:  142, Test:  141\n",
      "Electronic-- Train:  717, Validation:  142, Test:  141\n",
      "Experimental-- Train:  719, Validation:  141, Test:  140\n",
      "Folk-- Train:  721, Validation:  140, Test:  139\n",
      "Hip-Hop-- Train:  711, Validation:  145, Test:  144\n",
      "Instrumental-- Train:  718, Validation:  141, Test:  141\n",
      "International-- Train:  719, Validation:  141, Test:  140\n",
      "Jazz-- Train:  723, Validation:  139, Test:  138\n",
      "Pop-- Train:  718, Validation:  141, Test:  141\n",
      "Rock-- Train:  713, Validation:  144, Test:  143\n"
     ]
    }
   ],
   "source": [
    "# 0.3 from each genre\n",
    "for i in genres_songs_map.keys():\n",
    "    print(i+\"-- Train: % 2d, Validation: % 2d, Test: % 2d\"%(len(train[i]), len(validation[i]), len(test[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classical-- Train:  334, Validation:  11, Test:  11\n",
      "Electronic-- Train:  3020, Validation:  92, Test:  92\n",
      "Experimental-- Train:  3337, Validation:  107, Test:  106\n",
      "Folk-- Train:  1155, Validation:  35, Test:  34\n",
      "Hip-Hop-- Train:  713, Validation:  35, Test:  34\n",
      "Instrumental-- Train:  1374, Validation:  21, Test:  20\n",
      "International-- Train:  488, Validation:  17, Test:  16\n",
      "Jazz-- Train:  377, Validation:  7, Test:  6\n",
      "Pop-- Train:  1251, Validation:  24, Test:  23\n",
      "Rock-- Train:  2786, Validation:  140, Test:  139\n"
     ]
    }
   ],
   "source": [
    "# 0.2 from each genre\n",
    "for i in genres_songs_map.keys():\n",
    "    print(i+\"-- Train: % 2d, Validation: % 2d, Test: % 2d\"%(len(train[i]), len(validation[i]), len(test[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_default(obj):\n",
    "    if isinstance(obj, set):return list(obj)\n",
    "    raise TypeError\n",
    "file=json.dumps(train, sort_keys=True, indent=1, default=set_default)\n",
    "f = open('train.json', 'w')\n",
    "f.write(file)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_default(obj):\n",
    "    if isinstance(obj, set):return list(obj)\n",
    "    raise TypeError\n",
    "file=json.dumps(test, sort_keys=True, indent=1, default=set_default)\n",
    "f = open('test.json', 'w')\n",
    "f.write(file)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_default(obj):\n",
    "    if isinstance(obj, set):return list(obj)\n",
    "    raise TypeError\n",
    "file=json.dumps(validation, sort_keys=True, indent=1, default=set_default)\n",
    "f = open('validation.json', 'w')\n",
    "f.write(file)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_default(obj):\n",
    "    if isinstance(obj, set):return list(obj)\n",
    "    raise TypeError\n",
    "file=json.dumps(song_index_map, sort_keys=True, indent=1, default=set_default)\n",
    "f = open('song_index_map.json', 'w')\n",
    "f.write(file)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from scipy.sparse import csr_matrix\n",
    "A=csr_matrix((max(song_index_map.values())+1, max(song_index_map.values())+1),dtype = np.int8).toarray() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train:\n",
    "    for j in train[i]:\n",
    "        for k in train[i]:\n",
    "            if(j!=k): \n",
    "                A[song_index_map[j]][song_index_map[k]]=1\n",
    "                A[song_index_map[k]][song_index_map[j]]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "717"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train['Classical'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "features=pd.read_csv('features.csv')\n",
    "features=features.loc[3:]\n",
    "temp=dict()\n",
    "for i in features.to_numpy():\n",
    "    if(int(i[0]) in song_genres_map.keys()):temp[int(i[0])]=[float(item) for item in i[1:].tolist()]\n",
    "\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=list()\n",
    "for i in range(max(index_song_map.keys())+1):\n",
    "    X.append(temp[index_song_map[i]])\n",
    "X=np.asarray(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=X.shape[1])\n",
    "pca.fit(X)\n",
    "#print (pca.explained_variance_ratio_)\n",
    "#print (pca.explained_variance_ratio_.cumsum())\n",
    "pcount=0\n",
    "for i in pca.explained_variance_ratio_.cumsum():\n",
    "    pcount=pcount+1\n",
    "    if(i>=.95):\n",
    "        print(pcount)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "kpca=KernelPCA(n_components=X.shape[1])\n",
    "kpca_transform=kpca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187\n"
     ]
    }
   ],
   "source": [
    "explained_variance = np.var(kpca_transform, axis=0) \n",
    "explained_variance_ratio = explained_variance / np.sum(explained_variance) \n",
    "explained_variance_ratio\n",
    "kcount=0\n",
    "for i in explained_variance_ratio.cumsum():\n",
    "    kcount=kcount+1\n",
    "    if(i>=.95):\n",
    "        print(kcount)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpca=KernelPCA(n_components=kcount)\n",
    "X=kpca.fit_transform(X)\n",
    "# pca=PCA(n_components=count)\n",
    "# X=pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_song_id=list()\n",
    "for i in test.values():\n",
    "    for j in i:\n",
    "        test_song_id.append(j)\n",
    "train_song_id=list()\n",
    "for i in train.values():\n",
    "    for j in i:\n",
    "        train_song_id.append(j)\n",
    "validation_song_id=list()\n",
    "for i in validation.values():\n",
    "    for j in i:\n",
    "        validation_song_id.append(j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "for i in validation_song_id:\n",
    "    for j in train_song_id:\n",
    "        temp_val=1-spatial.distance.cosine(X[song_index_map[i]], X[song_index_map[j]])\n",
    "        if(temp_val>=0.75):\n",
    "            A[song_index_map[i]][song_index_map[j]]=1\n",
    "            A[song_index_map[j]][song_index_map[i]]=1\n",
    "#             print(str(song_genres_map[i])+\" \"+str(song_genres_map[j])+\" \"+str(temp_val))\n",
    "\n",
    "for i in test_song_id:\n",
    "    for j in train_song_id:\n",
    "        temp_val=1-spatial.distance.cosine(X[song_index_map[i]], X[song_index_map[j]])\n",
    "        if(temp_val>=0.75):\n",
    "            A[song_index_map[i]][song_index_map[j]]=1\n",
    "            A[song_index_map[j]][song_index_map[i]]=1\n",
    "            \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_index=dict()\n",
    "count=0\n",
    "for i in genres_songs_map.keys():\n",
    "    temp_index[i]=count\n",
    "    count=count+1\n",
    "Y=np.zeros((max(index_song_map.keys())+1, 10))\n",
    "for i in index_song_map:\n",
    "    for j in song_genres_map[index_song_map[i]]:\n",
    "        Y[i][temp_index[j]]=1\n",
    "\n",
    "train_bool=np.zeros((max(index_song_map.keys())+1,),dtype=bool)\n",
    "validation_bool=np.zeros((max(index_song_map.keys())+1,),dtype=bool)\n",
    "test_bool=np.zeros((max(index_song_map.keys())+1,),dtype=bool)\n",
    "\n",
    "for i in train_song_id: \n",
    "    train_bool[song_index_map[i]]=True\n",
    "for i in validation_song_id: \n",
    "    validation_bool[song_index_map[i]]=True\n",
    "for i in test_song_id: \n",
    "    test_bool[song_index_map[i]]=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph info:  Name: \n",
      "Type: Graph\n",
      "Number of nodes: 9711\n",
      "Number of edges: 4442918\n",
      "Average degree: 915.0279\n"
     ]
    }
   ],
   "source": [
    "A[A > 0] = 1\n",
    "G = nx.Graph(A)\n",
    "A = nx.adjacency_matrix(G)\n",
    "print('Graph info: ', nx.info(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import networkx as nx\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from spektral.layers import GraphConv\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dropout, Dense\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 279)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 9711)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_4 (GraphConv)        (None, 100)          27900       input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 100)          0           graph_conv_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_5 (GraphConv)        (None, 20)           2000        dropout_2[0][0]                  \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 20)           0           graph_conv_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_6 (GraphConv)        (None, 10)           200         dropout_3[0][0]                  \n",
      "                                                                 input_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 30,100\n",
      "Trainable params: 30,100\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "channel_1 = 100\n",
    "channel_2 = 20# Number of channels in the first layer\n",
    "dropout = 0.5           # Dropout rate for the features\n",
    "l2_reg = 5e-4           # L2 regularization rate\n",
    "learning_rate = 1e-2    # Learning rate\n",
    "epochs = 2000           # Number of training epochs\n",
    "es_patience = 10        # Patience for early stopping\n",
    "\n",
    "# Preprocessing operations\n",
    "A = GraphConv.preprocess(A).astype('f4')\n",
    "\n",
    "# Model definition\n",
    "X_in = Input(shape=(X.shape[1], ))\n",
    "fltr_in = Input((X.shape[0], ), sparse=True)\n",
    "\n",
    "graph_conv_1 = GraphConv(channel_1,\n",
    "                         activation='relu',\n",
    "                         kernel_regularizer=l2(l2_reg),\n",
    "                         use_bias=False)([X_in,fltr_in])\n",
    "\n",
    "dropout_1 = Dropout(dropout)(graph_conv_1)\n",
    "\n",
    "graph_conv_2 = GraphConv(channel_2,\n",
    "                         activation='relu',\n",
    "                         kernel_regularizer=l2(l2_reg),\n",
    "                         use_bias=False)([dropout_1, fltr_in])\n",
    "dropout_2 = Dropout(dropout)(graph_conv_2)\n",
    "\n",
    "\n",
    "graph_conv_3 = GraphConv(10,\n",
    "                         activation='softmax',\n",
    "                         use_bias=False)([dropout_2, fltr_in])\n",
    "\n",
    "# Build model\n",
    "model = Model(inputs=[X_in, fltr_in], outputs=graph_conv_3)\n",
    "optimizer = Adam(lr=learning_rate)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              weighted_metrics=['acc'])\n",
    "model.summary()\n",
    "\n",
    "tbCallBack_GCN = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir='./Tensorboard_GCN_FMA',\n",
    ")\n",
    "callback_GCN = [tbCallBack_GCN] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.5408 - acc: 0.0995 - val_loss: 0.4130 - val_acc: 0.2394\n",
      "Epoch 2/2000\n",
      "WARNING:tensorflow:From e:\\python\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.2895 - acc: 0.1820 - val_loss: 0.4021 - val_acc: 0.3270\n",
      "Epoch 3/2000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.1738 - acc: 0.3059 - val_loss: 0.3920 - val_acc: 0.3644\n",
      "Epoch 4/2000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.1208 - acc: 0.3212 - val_loss: 0.3806 - val_acc: 0.4040\n",
      "Epoch 5/2000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.0424 - acc: 0.3651 - val_loss: 0.3681 - val_acc: 0.4393\n",
      "Epoch 6/2000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.9831 - acc: 0.3775 - val_loss: 0.3547 - val_acc: 0.4760\n",
      "Epoch 7/2000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.8898 - acc: 0.4102 - val_loss: 0.3413 - val_acc: 0.5021\n",
      "Epoch 8/2000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.8355 - acc: 0.4017 - val_loss: 0.3291 - val_acc: 0.5141\n",
      "Epoch 9/2000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.7538 - acc: 0.4307 - val_loss: 0.3189 - val_acc: 0.5459\n",
      "Epoch 10/2000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.7087 - acc: 0.4360 - val_loss: 0.3112 - val_acc: 0.5565\n",
      "Epoch 11/2000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.6533 - acc: 0.4517 - val_loss: 0.3051 - val_acc: 0.5756\n",
      "Epoch 12/2000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.6298 - acc: 0.4587 - val_loss: 0.3002 - val_acc: 0.5925\n",
      "Epoch 13/2000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.5802 - acc: 0.4797 - val_loss: 0.2965 - val_acc: 0.6088\n",
      "Epoch 14/2000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.5410 - acc: 0.4982 - val_loss: 0.2937 - val_acc: 0.6236\n",
      "Epoch 15/2000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.5225 - acc: 0.5048 - val_loss: 0.2917 - val_acc: 0.6356\n",
      "Epoch 16/2000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.4656 - acc: 0.5286 - val_loss: 0.2901 - val_acc: 0.6405\n",
      "Epoch 17/2000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.4514 - acc: 0.5432 - val_loss: 0.2890 - val_acc: 0.6434\n",
      "Epoch 18/2000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.4082 - acc: 0.5597 - val_loss: 0.2885 - val_acc: 0.6455\n",
      "Epoch 19/2000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.3908 - acc: 0.5678 - val_loss: 0.2886 - val_acc: 0.6497\n",
      "Epoch 20/2000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.3637 - acc: 0.5908 - val_loss: 0.2889 - val_acc: 0.6532\n",
      "Epoch 21/2000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.3347 - acc: 0.5962 - val_loss: 0.2897 - val_acc: 0.6561\n",
      "Epoch 22/2000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2940 - acc: 0.6100 - val_loss: 0.2900 - val_acc: 0.6589\n",
      "Epoch 23/2000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2673 - acc: 0.6309 - val_loss: 0.2906 - val_acc: 0.6674\n",
      "Epoch 24/2000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2589 - acc: 0.6307 - val_loss: 0.2919 - val_acc: 0.6723\n",
      "Epoch 25/2000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2225 - acc: 0.6368 - val_loss: 0.2938 - val_acc: 0.6879\n",
      "Epoch 26/2000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2270 - acc: 0.6409 - val_loss: 0.2964 - val_acc: 0.6977\n",
      "Epoch 27/2000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2009 - acc: 0.6496 - val_loss: 0.2993 - val_acc: 0.6977\n",
      "Epoch 28/2000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2031 - acc: 0.6513 - val_loss: 0.3024 - val_acc: 0.6942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1872692cb00>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data = ([X, A], Y, validation_bool)\n",
    "model.fit([X, A],\n",
    "          Y,\n",
    "          sample_weight=train_bool,\n",
    "          epochs=epochs,\n",
    "          batch_size=X.shape[0],\n",
    "          validation_data=validation_data,\n",
    "          shuffle=False,\n",
    "          callbacks=[\n",
    "              EarlyStopping(patience=es_patience,  restore_best_weights=True),\n",
    "              tbCallBack_GCN\n",
    "          ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_te = X[test_bool]\n",
    "A_te = A[test_bool,:][:,test_bool]\n",
    "y_te = Y[test_bool]\n",
    "\n",
    "y_pred = model.predict([X_te, A_te], batch_size=X.shape[0])\n",
    "\n",
    "# y_pred=np.argmax(y_pred, axis=1)\n",
    "# y_te=np.argmax(y_te, axis=1)\n",
    "\n",
    "# count=0\n",
    "# for i in range(len(y_te)):\n",
    "#     if(y_te[i]==y_pred[i]):count=count+1\n",
    "# count/len(y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN Classification Report: \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    Classical       0.55      0.55      0.55       141\n",
      "   Electronic       0.36      0.33      0.34       141\n",
      " Experimental       0.34      0.33      0.34       140\n",
      "         Folk       0.36      0.37      0.37       139\n",
      "      Hip-Hop       0.51      0.65      0.57       144\n",
      " Instrumental       0.35      0.28      0.31       141\n",
      "International       0.39      0.40      0.40       140\n",
      "         Jazz       0.47      0.56      0.51       138\n",
      "          Pop       0.28      0.15      0.19       141\n",
      "         Rock       0.43      0.54      0.48       143\n",
      "\n",
      "     accuracy                           0.42      1408\n",
      "    macro avg       0.40      0.42      0.41      1408\n",
      " weighted avg       0.40      0.42      0.41      1408\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(np.argmax(y_te,axis=1), np.argmax(y_pred,axis=1), target_names=train.keys())\n",
    "print('GCN Classification Report: \\n {}'.format(report))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
