{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import networkx as nx\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from spektral.layers import GraphConv\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dropout, Dense\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classical-- 1000\n",
      "Electronic-- 1000\n",
      "Experimental-- 1000\n",
      "Folk-- 1000\n",
      "Hip-Hop-- 1000\n",
      "Instrumental-- 1000\n",
      "International-- 1000\n",
      "Jazz-- 1000\n",
      "Pop-- 1000\n",
      "Rock-- 1000\n"
     ]
    }
   ],
   "source": [
    "genres_songs_map=open(\"genres_vs_songs.json\")\n",
    "genres_songs_map=json.load(genres_songs_map)\n",
    "for i in genres_songs_map:\n",
    "    print(i+\"-- %d\"%(len(genres_songs_map[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9425\n",
      "283\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "song_index_map=dict()\n",
    "song_genres_map=dict()\n",
    "index_song_map=dict()\n",
    "for i in genres_songs_map.values():\n",
    "    for j in i:\n",
    "        song_genres_map[j]=list()\n",
    "for i in genres_songs_map:\n",
    "    for j in genres_songs_map[i]:\n",
    "        song_genres_map[j].append(i)\n",
    "aux=0\n",
    "for i in song_genres_map:\n",
    "    song_index_map[i]=aux\n",
    "    aux=aux+1\n",
    "for i in song_index_map:\n",
    "    index_song_map[song_index_map[i]]=i\n",
    "\n",
    "one_gener_song=list()\n",
    "more_than_one_gener_song=list()\n",
    "count_one=0\n",
    "count_two=0\n",
    "count_more_than_two=0\n",
    "for i in song_genres_map.values():\n",
    "    if(len(i)==1):count_one=count_one+1\n",
    "    elif(len(i)==2): count_two=count_two+1\n",
    "    else: count_more_than_two=count_more_than_two+1\n",
    "for i in song_genres_map:\n",
    "    if(len(song_genres_map[i])==1):one_gener_song.append(i)\n",
    "    else: more_than_one_gener_song.append(i)\n",
    "print(count_one)\n",
    "print(count_two)\n",
    "print(count_more_than_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=dict()\n",
    "test=dict()\n",
    "validation=dict()\n",
    "train=dict()\n",
    "for i in genres_songs_map.keys():\n",
    "    temp[i]=list()\n",
    "    test[i]=list()\n",
    "    validation[i]=list()\n",
    "    train[i]=list()\n",
    "for i in one_gener_song:\n",
    "    temp[song_genres_map[i][0]].append(i)\n",
    "\n",
    "import random\n",
    "from random import sample \n",
    "\n",
    "random.seed(1)\n",
    "for i in temp:\n",
    "    aux=sample(temp[i],int(len(temp[i])*0.3))\n",
    "    test[i]=aux[0:int(len(aux)/2)]\n",
    "    validation[i]=aux[int(len(aux)/2):]\n",
    "    for j in temp[i]:\n",
    "        if(j not in aux): train[i].append(j)\n",
    "for i in more_than_one_gener_song:\n",
    "    for j in song_genres_map[i]:\n",
    "        train[j].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classical-- Train:  717, Validation:  142, Test:  141\n",
      "Electronic-- Train:  717, Validation:  142, Test:  141\n",
      "Experimental-- Train:  719, Validation:  141, Test:  140\n",
      "Folk-- Train:  721, Validation:  140, Test:  139\n",
      "Hip-Hop-- Train:  711, Validation:  145, Test:  144\n",
      "Instrumental-- Train:  718, Validation:  141, Test:  141\n",
      "International-- Train:  719, Validation:  141, Test:  140\n",
      "Jazz-- Train:  723, Validation:  139, Test:  138\n",
      "Pop-- Train:  718, Validation:  141, Test:  141\n",
      "Rock-- Train:  713, Validation:  144, Test:  143\n"
     ]
    }
   ],
   "source": [
    "# 0.3 from each genre\n",
    "for i in genres_songs_map.keys():\n",
    "    print(i+\"-- Train: % 2d, Validation: % 2d, Test: % 2d\"%(len(train[i]), len(validation[i]), len(test[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_song_id=list()\n",
    "for i in test.values():\n",
    "    for j in i:\n",
    "        test_song_id.append(j)\n",
    "train_song_id=list()\n",
    "for i in train.values():\n",
    "    for j in i:\n",
    "        train_song_id.append(j)\n",
    "validation_song_id=list()\n",
    "for i in validation.values():\n",
    "    for j in i:\n",
    "        validation_song_id.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=[None for _ in range(10)]\n",
    "temp_index=dict()\n",
    "count=0\n",
    "for i in genres_songs_map.keys():\n",
    "    temp_index[i]=count\n",
    "    count=count+1\n",
    "for i in temp_index: classes[temp_index[i]]=i\n",
    "    \n",
    "Y=np.zeros((max(index_song_map.keys())+1, 10))\n",
    "for i in index_song_map:\n",
    "    for j in song_genres_map[index_song_map[i]]:\n",
    "        Y[i][temp_index[j]]=1/len(song_genres_map[index_song_map[i]])\n",
    "\n",
    "train_bool=np.zeros((max(index_song_map.keys())+1,),dtype=bool)\n",
    "validation_bool=np.zeros((max(index_song_map.keys())+1,),dtype=bool)\n",
    "test_bool=np.zeros((max(index_song_map.keys())+1,),dtype=bool)\n",
    "\n",
    "for i in index_song_map:\n",
    "    if(index_song_map[i] in train_song_id):train_bool[i]=True\n",
    "    elif(index_song_map[i] in validation_song_id):validation_bool[i]=True\n",
    "    else: test_bool[i]=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "features=pd.read_csv('features.csv')\n",
    "features=features.loc[3:]\n",
    "temp=dict()\n",
    "for i in features.to_numpy():\n",
    "    if(int(i[0]) in song_genres_map.keys()):temp[int(i[0])]=[float(item) for item in i[1:].tolist()]\n",
    "\n",
    "X=list()\n",
    "for i in range(max(index_song_map.keys())+1):\n",
    "    X.append(temp[index_song_map[i]])\n",
    "X=np.asarray(X)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "X = StandardScaler().fit_transform(X)\n",
    "pca=PCA(n_components=187)\n",
    "X=pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from scipy.sparse import csr_matrix\n",
    "A=csr_matrix((max(song_index_map.values())+1, max(song_index_map.values())+1),dtype = np.int8).toarray() \n",
    "for i in train:\n",
    "    for j in train[i]:\n",
    "        for k in train[i]:\n",
    "            if(j!=k): \n",
    "                A[song_index_map[j]][song_index_map[k]]=1\n",
    "                A[song_index_map[k]][song_index_map[j]]=1\n",
    "\n",
    "from scipy import spatial\n",
    "\n",
    "for i in validation_song_id:\n",
    "    for j in train_song_id:\n",
    "        temp_val=1-spatial.distance.cosine(X[song_index_map[i]], X[song_index_map[j]])\n",
    "        if(temp_val>=0.5):\n",
    "            A[song_index_map[i]][song_index_map[j]]=1\n",
    "            A[song_index_map[j]][song_index_map[i]]=1\n",
    "#             print(str(song_genres_map[i])+\" \"+str(song_genres_map[j])+\" \"+str(temp_val))\n",
    "\n",
    "for i in test_song_id:\n",
    "    for j in train_song_id:\n",
    "        temp_val=1-spatial.distance.cosine(X[song_index_map[i]], X[song_index_map[j]])\n",
    "        if(temp_val>=0.5):\n",
    "            A[song_index_map[i]][song_index_map[j]]=1\n",
    "            A[song_index_map[j]][song_index_map[i]]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph info:  Name: \n",
      "Type: Graph\n",
      "Number of nodes: 9711\n",
      "Number of edges: 2714045\n",
      "Average degree: 558.9630\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "A[A > 0] = 1\n",
    "G = nx.Graph(A)\n",
    "A = nx.adjacency_matrix(G)\n",
    "print('Graph info: ', nx.info(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 187)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 9711)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_4 (GraphConv)        (None, 100)          18700       input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 100)          0           graph_conv_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "graph_conv_5 (GraphConv)        (None, 10)           1000        dropout_2[0][0]                  \n",
      "                                                                 input_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 19,700\n",
      "Trainable params: 19,700\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "channel_1 = 100\n",
    "channel_2 = 20# Number of channels in the first layer\n",
    "dropout = 0.9          # Dropout rate for the features\n",
    "l2_reg = 5e-4           # L2 regularization rate\n",
    "learning_rate = 1e-2    # Learning rate\n",
    "epochs = 2000           # Number of training epochs\n",
    "es_patience = 10        # Patience for early stopping\n",
    "\n",
    "# Preprocessing operations\n",
    "A = GraphConv.preprocess(A).astype('f4')\n",
    "\n",
    "# Model definition\n",
    "X_in = Input(shape=(X.shape[1], ))\n",
    "fltr_in = Input((X.shape[0], ), sparse=True)\n",
    "\n",
    "graph_conv_1 = GraphConv(channel_1,\n",
    "                         activation='relu',\n",
    "                         kernel_regularizer=l2(l2_reg),\n",
    "                         use_bias=False)([X_in,fltr_in])\n",
    "\n",
    "dropout_1 = Dropout(dropout)(graph_conv_1)\n",
    "\n",
    "# graph_conv_2 = GraphConv(channel_2,\n",
    "#                          activation='relu',\n",
    "#                          kernel_regularizer=l2(l2_reg),\n",
    "#                          use_bias=False)([dropout_1, fltr_in])\n",
    "# dropout_2 = Dropout(dropout)(graph_conv_2)\n",
    "\n",
    "\n",
    "graph_conv_3 = GraphConv(10,\n",
    "                         activation='softmax',\n",
    "                         use_bias=False)([dropout_1, fltr_in])\n",
    "\n",
    "# Build model\n",
    "model = Model(inputs=[X_in, fltr_in], outputs=graph_conv_3)\n",
    "optimizer = Adam(lr=learning_rate)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              weighted_metrics=['acc'])\n",
    "model.summary()\n",
    "\n",
    "tbCallBack_GCN = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir='./Tensorboard_GCN_FMA',\n",
    ")\n",
    "callback_GCN = [tbCallBack_GCN] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.3265 - acc: 0.1041 - val_loss: 0.4682 - val_acc: 0.1448\n",
      "Epoch 2/2000\n",
      "1/1 [==============================] - 1s 507ms/step - loss: 2.8808 - acc: 0.1301 - val_loss: 0.4188 - val_acc: 0.2076\n",
      "Epoch 3/2000\n",
      "1/1 [==============================] - 1s 504ms/step - loss: 2.5496 - acc: 0.1546 - val_loss: 0.3913 - val_acc: 0.2535\n",
      "Epoch 4/2000\n",
      "1/1 [==============================] - 0s 495ms/step - loss: 2.2223 - acc: 0.1931 - val_loss: 0.3760 - val_acc: 0.2733\n",
      "Epoch 5/2000\n",
      "1/1 [==============================] - 1s 528ms/step - loss: 2.0829 - acc: 0.2197 - val_loss: 0.3666 - val_acc: 0.2895\n",
      "Epoch 6/2000\n",
      "1/1 [==============================] - 0s 497ms/step - loss: 1.8676 - acc: 0.2660 - val_loss: 0.3604 - val_acc: 0.2980\n",
      "Epoch 7/2000\n",
      "1/1 [==============================] - 0s 499ms/step - loss: 1.7245 - acc: 0.2791 - val_loss: 0.3556 - val_acc: 0.3150\n",
      "Epoch 8/2000\n",
      "1/1 [==============================] - 1s 513ms/step - loss: 1.6186 - acc: 0.3133 - val_loss: 0.3514 - val_acc: 0.3220\n",
      "Epoch 9/2000\n",
      "1/1 [==============================] - 0s 499ms/step - loss: 1.5605 - acc: 0.3316 - val_loss: 0.3476 - val_acc: 0.3263\n",
      "Epoch 10/2000\n",
      "1/1 [==============================] - 1s 550ms/step - loss: 1.4745 - acc: 0.3559 - val_loss: 0.3445 - val_acc: 0.3362\n",
      "Epoch 11/2000\n",
      "1/1 [==============================] - 0s 498ms/step - loss: 1.4447 - acc: 0.3663 - val_loss: 0.3422 - val_acc: 0.3404\n",
      "Epoch 12/2000\n",
      "1/1 [==============================] - 0s 496ms/step - loss: 1.3688 - acc: 0.4076 - val_loss: 0.3404 - val_acc: 0.3404\n",
      "Epoch 13/2000\n",
      "1/1 [==============================] - 1s 511ms/step - loss: 1.3694 - acc: 0.3958 - val_loss: 0.3392 - val_acc: 0.3432\n",
      "Epoch 14/2000\n",
      "1/1 [==============================] - 1s 512ms/step - loss: 1.3294 - acc: 0.4192 - val_loss: 0.3386 - val_acc: 0.3439\n",
      "Epoch 15/2000\n",
      "1/1 [==============================] - 0s 494ms/step - loss: 1.3012 - acc: 0.4244 - val_loss: 0.3386 - val_acc: 0.3411\n",
      "Epoch 16/2000\n",
      "1/1 [==============================] - 1s 579ms/step - loss: 1.2777 - acc: 0.4326 - val_loss: 0.3389 - val_acc: 0.3397\n",
      "Epoch 17/2000\n",
      "1/1 [==============================] - 0s 496ms/step - loss: 1.2776 - acc: 0.4478 - val_loss: 0.3395 - val_acc: 0.3383\n",
      "Epoch 18/2000\n",
      "1/1 [==============================] - 0s 496ms/step - loss: 1.2400 - acc: 0.4623 - val_loss: 0.3405 - val_acc: 0.3383\n",
      "Epoch 19/2000\n",
      "1/1 [==============================] - 0s 499ms/step - loss: 1.2227 - acc: 0.4687 - val_loss: 0.3418 - val_acc: 0.3383\n",
      "Epoch 20/2000\n",
      "1/1 [==============================] - 1s 570ms/step - loss: 1.2277 - acc: 0.4671 - val_loss: 0.3431 - val_acc: 0.3376\n",
      "Epoch 21/2000\n",
      "1/1 [==============================] - 0s 498ms/step - loss: 1.2307 - acc: 0.4617 - val_loss: 0.3445 - val_acc: 0.3404\n",
      "Epoch 22/2000\n",
      "1/1 [==============================] - 1s 513ms/step - loss: 1.2113 - acc: 0.4734 - val_loss: 0.3459 - val_acc: 0.3418\n",
      "Epoch 23/2000\n",
      "1/1 [==============================] - 0s 497ms/step - loss: 1.1940 - acc: 0.4842 - val_loss: 0.3472 - val_acc: 0.3418\n",
      "Epoch 24/2000\n",
      "1/1 [==============================] - 0s 496ms/step - loss: 1.1904 - acc: 0.4879 - val_loss: 0.3487 - val_acc: 0.3439\n",
      "Epoch 25/2000\n",
      "1/1 [==============================] - 1s 559ms/step - loss: 1.1702 - acc: 0.4908 - val_loss: 0.3504 - val_acc: 0.3460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ac253c5908>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data = ([X, A], Y, validation_bool)\n",
    "model.fit([X, A],\n",
    "          Y,\n",
    "          sample_weight=train_bool,\n",
    "          epochs=epochs,\n",
    "          batch_size=X.shape[0],\n",
    "          validation_data=validation_data,\n",
    "          shuffle=False,\n",
    "          callbacks=[\n",
    "              EarlyStopping(patience=es_patience,  restore_best_weights=True),\n",
    "              tbCallBack_GCN\n",
    "          ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN Classification Report: \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    Classical       0.52      0.55      0.53       141\n",
      "   Electronic       0.26      0.33      0.29       141\n",
      " Experimental       0.23      0.16      0.19       140\n",
      "         Folk       0.32      0.35      0.33       139\n",
      "      Hip-Hop       0.42      0.53      0.46       144\n",
      " Instrumental       0.26      0.22      0.24       141\n",
      "International       0.39      0.29      0.33       140\n",
      "         Jazz       0.37      0.41      0.39       138\n",
      "          Pop       0.25      0.15      0.19       141\n",
      "         Rock       0.37      0.49      0.42       143\n",
      "\n",
      "     accuracy                           0.35      1408\n",
      "    macro avg       0.34      0.35      0.34      1408\n",
      " weighted avg       0.34      0.35      0.34      1408\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_te = X[test_bool]\n",
    "A_te = A[test_bool,:][:,test_bool]\n",
    "y_te = Y[test_bool]\n",
    "\n",
    "y_pred = model.predict([X_te, A_te], batch_size=X.shape[0])\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(np.argmax(y_te,axis=1), np.argmax(y_pred,axis=1), target_names=classes)\n",
    "print('GCN Classification Report: \\n {}'.format(report))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 0.2 from each genre\n",
    "# for i in genres_songs_map.keys():\n",
    "#     print(i+\"-- Train: % 2d, Validation: % 2d, Test: % 2d\"%(len(train[i]), len(validation[i]), len(test[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def set_default(obj):\n",
    "#     if isinstance(obj, set):return list(obj)\n",
    "#     raise TypeError\n",
    "# file=json.dumps(train, sort_keys=True, indent=1, default=set_default)\n",
    "# f = open('train.json', 'w')\n",
    "# f.write(file)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def set_default(obj):\n",
    "#     if isinstance(obj, set):return list(obj)\n",
    "#     raise TypeError\n",
    "# file=json.dumps(test, sort_keys=True, indent=1, default=set_default)\n",
    "# f = open('test.json', 'w')\n",
    "# f.write(file)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def set_default(obj):\n",
    "#     if isinstance(obj, set):return list(obj)\n",
    "#     raise TypeError\n",
    "# file=json.dumps(validation, sort_keys=True, indent=1, default=set_default)\n",
    "# f = open('validation.json', 'w')\n",
    "# f.write(file)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def set_default(obj):\n",
    "#     if isinstance(obj, set):return list(obj)\n",
    "#     raise TypeError\n",
    "# file=json.dumps(song_index_map, sort_keys=True, indent=1, default=set_default)\n",
    "# f = open('song_index_map.json', 'w')\n",
    "# f.write(file)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pca = PCA(n_components=X.shape[1])\n",
    "# pca.fit(X)\n",
    "# #print (pca.explained_variance_ratio_)\n",
    "# #print (pca.explained_variance_ratio_.cumsum())\n",
    "# pcount=0\n",
    "# for i in pca.explained_variance_ratio_.cumsum():\n",
    "#     pcount=pcount+1\n",
    "#     if(i>=.95):\n",
    "#         print(pcount)\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import KernelPCA\n",
    "# kpca=KernelPCA(n_components=X.shape[1])\n",
    "# kpca_transform=kpca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explained_variance = np.var(kpca_transform, axis=0) \n",
    "# explained_variance_ratio = explained_variance / np.sum(explained_variance) \n",
    "# explained_variance_ratio\n",
    "# kcount=0\n",
    "# for i in explained_variance_ratio.cumsum():\n",
    "#     kcount=kcount+1\n",
    "#     if(i>=.98):\n",
    "#         print(kcount)\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kpca=KernelPCA(n_components=kcount)\n",
    "# X=kpca.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
